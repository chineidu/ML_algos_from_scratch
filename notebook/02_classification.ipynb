{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes From Scratch\n",
    "\n",
    "* `Naive Bayes` Algorithm is based on the `Bayes` Theorem which states that the probability of A given B equals the probability of B given A multiplied by probability of A divided by probability of B. i.e\n",
    "\n",
    "$$\n",
    "p(A | B) = \\frac{p(B | A). p(A)}{p(B)}\n",
    "$$\n",
    "\n",
    "* Applying Bayes' Theorem to ML, we have:\n",
    "\n",
    "$$\n",
    "p(y | X) = \\frac{p(X | y). p(y)}{p(X)}\n",
    "$$\n",
    "\n",
    "where:\n",
    "  * $p(y | X)$: Posterior probability\n",
    "  * $p(X | y)$: Class-conditional probability\n",
    "  * $p(y)$: Prior probability of y\n",
    "  * $p(X)$: Prior probability of X\n",
    "\n",
    "* Note:\n",
    "\n",
    "$$\n",
    "Posterior probability = Class-conditional probability + Prior probability of y\n",
    "$$\n",
    "\n",
    "* It's a `naive` algorithm because it assumes that the features are mutually independent (which might not be true).\n",
    "* Expanding Bayes' theorem yields:\n",
    "\n",
    "$$\n",
    "p(y | X) = \\frac{p(x_{1} | y).p(x_{2} | y)...p(x_{n} | y). p(y)}{p(X)}\n",
    "$$\n",
    "\n",
    "* Since p(X) does NOT depend on `y`, we can drop it.\n",
    "* In order to determine `y`, we need to find the argmax of the posterior. i.e\n",
    "  \n",
    "$$\n",
    "p(y | X) = \\argmax(p(x_{1} | y).p(x_{2} | y)...p(x_{n} | y). p(y))\n",
    "$$\n",
    "\n",
    "* Since the product of the probabilities will yield a very small value (very close 0), we need to find the `log` of the posterior so that we avoid overflow error. \n",
    "\n",
    "$$\n",
    "p(y | X) = \\argmax(logp(x_{1} | y).logp(x_{2} | y)...logp(x_{n} | y). logp(y))\n",
    "$$\n",
    "\n",
    "* Log of the conditional probability can be modelled using a `Probability Density Function`.\n",
    "\n",
    "$$\n",
    "p(X | y) = (\\frac{\\exp({- \\frac{(x_{i} - \\mu_{y})}{2\\sigma_{y}^2}})}{\\sqrt{2\\pi\\sigma_{y}^2}})\n",
    "$$\n",
    "\n",
    "where:\n",
    "  * $\\mu_{y}$ is the mean given a class. i.e when class=0 or 1.\n",
    "  * $p\\sigma_{y}^2$: is the variance given a class. i.e when class=0 or 1.\n",
    "\n",
    "* Therefore, `y` is:\n",
    "\n",
    "$$\n",
    "y = \\argmax({\\sum_{i=1}^{N}{log(\\frac{\\exp({-\\frac{(x_{i} - \\mu_{y})}{2\\sigma_{y}^2}})}{\\sqrt{2\\pi\\sigma_{y}^2}}) + log(p(y))}})\n",
    "$$\n",
    "\n",
    "* Since we have a binary class, for each input, the index of the value that produces the highest probability (argmax) is the the predicted value of `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Black code formatter (Optional)\n",
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6cfa5e2e7f6473d0731a0f2d805e3c50a81965be55a72eefbad345a8551b801f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
